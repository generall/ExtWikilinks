{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PredictorBase:\n",
    "    \"\"\"\n",
    "    This class contains implementation of experiment design.\n",
    "    It passes few instances with classes to the `train` method, then it passes validation instances to predict\n",
    "    method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Clear info about previous bathces\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train on few entities. Override this method in real implementation\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict classes of the given entities\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    batch_size = 10\n",
    "    test_fraction = 0.3\n",
    "    \n",
    "    @classmethod\n",
    "    def read_lines(cls, fd):\n",
    "        for line in fd:\n",
    "            yield line.decode().strip('\\n').split('\\t')\n",
    "    \n",
    "    def __init__(self, filename=\"./shuffled_dedup_entities.tsv.gz\"):\n",
    "        self.fd = gzip.open(filename, 'r')\n",
    "        self.reader = self.read_lines(self.fd)\n",
    "        \n",
    "        \n",
    "    def read_batch(self, size=None):\n",
    "        batch = list(itertools.islice(self.reader, size or self.batch_size))\n",
    "        \n",
    "        groups = defaultdict(list)\n",
    "        for entity in batch:\n",
    "            groups[entity[0]].append(entity)\n",
    "            \n",
    "        train_groups = {}\n",
    "        test_groups = {}\n",
    "        for etype, entities in groups.items():\n",
    "            if len(entities) * self.test_fraction > 1:\n",
    "                test_size = int(len(entities) * self.test_fraction)\n",
    "                test_groups[etype] = entities[:test_size]\n",
    "                train_groups[etype] = entities[test_size:]\n",
    "        \n",
    "        return train_groups, test_groups\n",
    "    \n",
    "    @classmethod\n",
    "    def prepare_data(cls, group):\n",
    "        X, y = [], []\n",
    "        for label, entities in group.items():\n",
    "            for entity in entities:\n",
    "                X.append((entity[1], entity[3]))\n",
    "                y.append(label)\n",
    "\n",
    "        c = list(zip(X, y))\n",
    "\n",
    "        random.shuffle(c)\n",
    "\n",
    "        X, y = zip(*c)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def eval_batched(self, model, metric, entities_count, count):\n",
    "        metrics = []\n",
    "        for batch_id in range(count):\n",
    "            train, test = eva.read_batch(entities_count)\n",
    "            X, y = Evaluator.prepare_data(train)\n",
    "            X_test, y_test = Evaluator.prepare_data(test)\n",
    "            model.train(X, y)\n",
    "            pred = model.predict(X_test)\n",
    "            score = metric(pred, y_test)\n",
    "            metrics.append(score)\n",
    "        return np.mean(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_context(X):\n",
    "    return np.array(list(map(\n",
    "        lambda x: x[0] + \" \" + x[1],\n",
    "        X\n",
    "    )))\n",
    "\n",
    "class KNNBaseline(PredictorBase):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.clear()\n",
    "    \n",
    "    def clear(self):\n",
    "        self.model = Pipeline([\n",
    "            ('concat_context', FunctionTransformer(concat_context)),\n",
    "            ('vectorizer', CountVectorizer(stop_words='english')),\n",
    "            ('cls', KNeighborsClassifier(metric='cosine', algorithm='brute'))\n",
    "        ])\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score = eva.eval_batched(\n",
    "    model=KNNBaseline(),\n",
    "    metric=lambda x, y: f1_score(x, y, average='micro'),\n",
    "    entities_count=1000,\n",
    "    count=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68707437656001968"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
